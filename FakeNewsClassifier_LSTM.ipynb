{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ICvo2RsD6wEJ"
      },
      "outputs": [],
      "source": [
        "# LSTM Fake News Classification Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we ant to fix random seed for reproducibility of our results\n",
        "# seed = 0\n",
        "# np.random.seed(seed)\n",
        "# tf.random.set_seed(0)"
      ],
      "metadata": {
        "id": "Ntu0J0bN_h7C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the training dataset from Github\n",
        "dataset_location = 'https://raw.githubusercontent.com/SeunAjao/FakeNewsClassifier/main/charlie.tsv'\n",
        "data_set = pd.read_csv(dataset_location, sep = '\\t', quoting = 3, header = None)\n",
        "X = data_set.iloc[:, 0]\n",
        "Y = data_set.iloc[:, 1]\n"
      ],
      "metadata": {
        "id": "1oZwcwKC_36X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that you have correctlly imported n number of rows. Thee should be only two columns for each of the datasets\n",
        "print(data_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYIcTvHYlJKm",
        "outputId": "6e26c99d-7cce-4766-d836-90e16c7d4ccc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2067, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwkJjF5O8B6r",
        "outputId": "9f96af75-2836-43e5-eb89-fde30108dc79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                      0  1\n",
            "0     Breaking: At least 10 dead, 5 injured after tO...  1\n",
            "1     France: 10 people dead after shooting at HQ of...  1\n",
            "2     Ten killed in shooting at headquarters of Fren...  1\n",
            "3     BREAKING: 10 dead in shooting at headquarters ...  1\n",
            "4     Reuters: 10 people shot dead at headquarters o...  1\n",
            "...                                                 ... ..\n",
            "2062  Some hostages seen leaving Paris kosher market...  0\n",
            "2063  Gunman holding hostages at kosher supermarket ...  0\n",
            "2064  Respect to the French Police #JeSuisCharliehtt...  0\n",
            "2065  MORE: Police official: Suspects in Charlie Heb...  0\n",
            "2066  #BREAKING - Both #CharlieHebdo suspects killed...  0\n",
            "\n",
            "[2067 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the training texts and make it sequential\n",
        "top_words = 50\n",
        "tokenizer = Tokenizer(num_words=top_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "sequences_train = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "0nhs2VOTAACU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the testing texts and make it sequential\n",
        "tokenizer.fit_on_texts(X)\n",
        "sequences_test = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "74xD5_zWAJkB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word_index_train = tokenizer.word_index_train\n",
        "#print('Found %s unique tokens.' % len(word_index_train))\n",
        "# Y = Y.values.reshape(2600,)\n",
        "# print(Y.shape)"
      ],
      "metadata": {
        "id": "pHnkL_e5AQPC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# truncate and pad input sequences to a 300 characters per tweet\n",
        "max_tweet_length = 300\n",
        "X = sequence.pad_sequences(sequences_train, maxlen=max_tweet_length)"
      ],
      "metadata": {
        "id": "0OxCrQxxAS9C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define 10-fold cross validation test harness\n",
        "#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed) the random stste argument would make our results reproducible\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "cvscores = []"
      ],
      "metadata": {
        "id": "jcxtAOOkAcwn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training split data\n",
        "for train, test in kfold.split(X, Y):\n",
        "\t# create the model\n",
        "\tembedding_vector_length = 32\n",
        "\tmodel = Sequential()\n",
        "\t# load the dataset with word embedding but only keep the top n words, zero the rest\n",
        "\tmodel.add(Embedding(top_words, embedding_vector_length, input_length=max_tweet_length))"
      ],
      "metadata": {
        "id": "h0azSYgpBRj1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\t# create the model object\n",
        "\tembedding_vector_length = 32\n",
        "\tmodel = Sequential()"
      ],
      "metadata": {
        "id": "ttceTg5VAdlQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset with word embedding but only keep the top n words, zero the rest\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_tweet_length))\n"
      ],
      "metadata": {
        "id": "V5MjyqoHAdob"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create our evaluation metrics for our model within Keras\n",
        "\n",
        "# Model Precision: TP / (TP + FP)\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "# Model Recall: TP / (TP + FN)\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "# Model FMeasure: 2 TP / (2 TP + FP + FN)\n",
        "def fmeasure(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    f1 = 2 * (p * r) / (p + r + K.epsilon())\n",
        "    return f1\n",
        "\n"
      ],
      "metadata": {
        "id": "roILkzpeeeGJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics =['accuracy', precision, recall, fmeasure])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6fKmQ3omv0S",
        "outputId": "d8e7b374-2b74-46a4-a1c2-ee88e58e0cde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 300, 32)           1600      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               53200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54901 (214.46 KB)\n",
            "Trainable params: 54901 (214.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's fit the model with 20 epochs..you may choose to train for longer if it gets better bute remember to avoid overfitting.\n",
        "# The default train-test split in Keras is 80:20 but we will use a 70:30 split for our task\n",
        "\n",
        "model.fit(X[train], Y[train], epochs=20, batch_size=64, validation_split =0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NR_pcwvtEj9",
        "outputId": "8aa7646d-19ce-46da-e672-4388b024f9e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "21/21 [==============================] - 27s 853ms/step - loss: 0.6433 - accuracy: 0.6813 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00 - val_loss: 0.4095 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 2/20\n",
            "21/21 [==============================] - 11s 555ms/step - loss: 0.5975 - accuracy: 0.6828 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00 - val_loss: 0.3992 - val_accuracy: 1.0000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 3/20\n",
            "21/21 [==============================] - 9s 424ms/step - loss: 0.5145 - accuracy: 0.7435 - precision: 0.5346 - recall: 0.2634 - fmeasure: 0.3325 - val_loss: 0.2868 - val_accuracy: 0.8766 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 4/20\n",
            "21/21 [==============================] - 12s 570ms/step - loss: 0.4431 - accuracy: 0.7926 - precision: 0.8110 - recall: 0.5616 - fmeasure: 0.6261 - val_loss: 0.5513 - val_accuracy: 0.7084 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 5/20\n",
            "21/21 [==============================] - 11s 524ms/step - loss: 0.4340 - accuracy: 0.8280 - precision: 0.7705 - recall: 0.6571 - fmeasure: 0.6968 - val_loss: 0.4666 - val_accuracy: 0.7674 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 6/20\n",
            "21/21 [==============================] - 10s 446ms/step - loss: 0.4344 - accuracy: 0.8195 - precision: 0.8327 - recall: 0.5328 - fmeasure: 0.6443 - val_loss: 0.4262 - val_accuracy: 0.7764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 7/20\n",
            "21/21 [==============================] - 12s 571ms/step - loss: 0.4082 - accuracy: 0.8326 - precision: 0.8416 - recall: 0.5883 - fmeasure: 0.6846 - val_loss: 0.4801 - val_accuracy: 0.7424 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 8/20\n",
            "21/21 [==============================] - 10s 501ms/step - loss: 0.3887 - accuracy: 0.8372 - precision: 0.7971 - recall: 0.6540 - fmeasure: 0.7111 - val_loss: 0.5323 - val_accuracy: 0.7335 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 9/20\n",
            "21/21 [==============================] - 10s 489ms/step - loss: 0.3736 - accuracy: 0.8425 - precision: 0.7983 - recall: 0.6729 - fmeasure: 0.7254 - val_loss: 0.5631 - val_accuracy: 0.7352 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 10/20\n",
            "21/21 [==============================] - 13s 609ms/step - loss: 0.3626 - accuracy: 0.8564 - precision: 0.8340 - recall: 0.6918 - fmeasure: 0.7521 - val_loss: 0.5861 - val_accuracy: 0.7335 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 11/20\n",
            "21/21 [==============================] - 11s 508ms/step - loss: 0.3539 - accuracy: 0.8618 - precision: 0.8250 - recall: 0.7047 - fmeasure: 0.7557 - val_loss: 0.6631 - val_accuracy: 0.7227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 12/20\n",
            "21/21 [==============================] - 11s 526ms/step - loss: 0.3467 - accuracy: 0.8641 - precision: 0.8376 - recall: 0.7107 - fmeasure: 0.7633 - val_loss: 0.6758 - val_accuracy: 0.7335 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 13/20\n",
            "21/21 [==============================] - 13s 639ms/step - loss: 0.3420 - accuracy: 0.8656 - precision: 0.8437 - recall: 0.7194 - fmeasure: 0.7707 - val_loss: 0.7147 - val_accuracy: 0.7370 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 14/20\n",
            "21/21 [==============================] - 12s 575ms/step - loss: 0.3374 - accuracy: 0.8687 - precision: 0.8612 - recall: 0.7015 - fmeasure: 0.7689 - val_loss: 0.7523 - val_accuracy: 0.7370 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 15/20\n",
            "21/21 [==============================] - 10s 492ms/step - loss: 0.3336 - accuracy: 0.8725 - precision: 0.8346 - recall: 0.7185 - fmeasure: 0.7691 - val_loss: 0.7707 - val_accuracy: 0.7352 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 16/20\n",
            "21/21 [==============================] - 11s 503ms/step - loss: 0.3330 - accuracy: 0.8687 - precision: 0.8520 - recall: 0.7044 - fmeasure: 0.7633 - val_loss: 0.8256 - val_accuracy: 0.7299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 17/20\n",
            "21/21 [==============================] - 12s 578ms/step - loss: 0.3292 - accuracy: 0.8725 - precision: 0.8668 - recall: 0.6910 - fmeasure: 0.7611 - val_loss: 0.8214 - val_accuracy: 0.7299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 18/20\n",
            "21/21 [==============================] - 10s 491ms/step - loss: 0.3272 - accuracy: 0.8694 - precision: 0.8564 - recall: 0.7157 - fmeasure: 0.7752 - val_loss: 0.8360 - val_accuracy: 0.7317 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 19/20\n",
            "21/21 [==============================] - 11s 494ms/step - loss: 0.3256 - accuracy: 0.8717 - precision: 0.8663 - recall: 0.7061 - fmeasure: 0.7728 - val_loss: 0.8971 - val_accuracy: 0.7281 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
            "Epoch 20/20\n",
            "21/21 [==============================] - 12s 578ms/step - loss: 0.3235 - accuracy: 0.8702 - precision: 0.8634 - recall: 0.7065 - fmeasure: 0.7707 - val_loss: 0.9104 - val_accuracy: 0.7263 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79db364d1ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the training data into 80% and 20% portions with random state for reproducibility\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0) # 80% training and 20% test"
      ],
      "metadata": {
        "id": "HE7VO5PLlzRx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the dimension of your output from above\n",
        "#print(X_train.shape)\n",
        "#print(X_test.shape)\n",
        "#print(Y_train.shape)\n",
        "#print(Y_test.shape)"
      ],
      "metadata": {
        "id": "UAec4GkZum8S"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can check model performance and see what your results are\n",
        "# Train the model using the 80:20 train-split\n",
        "#clf = model.fit(X_train, Y_train, epochs=0, batch_size=64)"
      ],
      "metadata": {
        "id": "9GbCelcnlOdY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance here will vary from the CV option we are adopting from the lab...possibly lower\n",
        "# Predict the response for test dataset\n",
        "#Y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "jzcQ3U9unCP9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final evaluation of the model\n",
        "scores = model.evaluate(X[test], Y[test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo-1jbmul-yb",
        "outputId": "f7f3cd47-17b4-48b0-eb4a-6e1c241ee291"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 61ms/step - loss: 0.5538 - accuracy: 0.8155 - precision: 0.2619 - recall: 0.1902 - fmeasure: 0.2171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[test].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "164ytADjCRUa",
        "outputId": "884f905b-6e5a-4130-eef4-704e0ca9306d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(206, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[train].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVZvWenMCeHG",
        "outputId": "d42db3e0-180b-4979-8e47-571d5f8d21af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1861, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the evaluation scores of your model\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"Precision: %.2f%%\" % (scores[2]*100))\n",
        "print(\"Recall: %.2f%%\" % (scores[3]*100))\n",
        "print(\"Fmeasure: %.2f%%\" % (scores[4]*100))\n",
        "print(scores)\n",
        "\n",
        "# Your more reliable cross validation accuracy\n",
        "cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uDen_yVa61R1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ecd8a4-9eab-424b-e78e-62066bf095a4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 81.55%\n",
            "Precision: 26.19%\n",
            "Recall: 19.02%\n",
            "Fmeasure: 21.71%\n",
            "[0.5537721514701843, 0.8155339956283569, 0.2619047462940216, 0.19024726748466492, 0.21714285016059875]\n",
            "81.55% (+/- 0.00%)\n"
          ]
        }
      ]
    }
  ]
}